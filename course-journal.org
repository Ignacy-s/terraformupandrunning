* Wed 29 Mar 2023 05:43:25 PM CEST
Starting with the Terraform book. Skipped to first exercise.
Setting up a simple web server on a VM in AWS.

* Chapter 2. Getting Started with Terraform
** Setting up your AWS account
*** Go to https://aws.amazon.com and set log in/create account.
*** Create an AWS access key and save it in password manager.
** Installing Terraform
*** Installing directly on desktop (instead of inside a VM). I have a feeling that Terraform installation wont pull too many dependencies, so I don't have to install it inside a VM like I would with some java or javascript developer environment.
**** Installing on Fedora
***** There is a repo package with version 1.4.4. Confirmed on Hashicorp's GitHub releases page that it is the latest version. Looks like a point for Fedora here.
***** There is also an emacs-terraform package. But maybe it would be better to install it from MELPA or ELPA (Emacs' own package repositories).
****** Chose to install it from Emacs' own repos.
**** Installing on Ubuntu
I already know that the latest package version is 1.4.4.

Ubuntu's version is 1.3.7

Checking if there are any big changes in 1.4 release that justify
adding Terraform PPA.

Don't see any.
** Setting environment variables with AWS access keys so Terraform can use AWS.
# We don't want keys in bash history. After entering the secret you
# need to press Ctrl-D to tell cat we've stopped writing.
export AWS_ACCESS_KEY_ID="$(cat -)" \
  && export AWS_SECRET_ACCESS_KEY="$(cat -)"

** Deploying a single server
*** Choosing AWS region
Chosen Stockholm (eu-north-1) because it's close and cheap. Read [[https://www.concurrencylabs.com/blog/choose-your-aws-region-wisely/][this article]] to learn about it.
*** Choosing server AMI
AMI is an image id in amazon AWS slang. AWS folks love three letter
acronyms :)

Used: EC2 console > Launch New Instance [[https://eu-north-1.console.aws.amazon.com/ec2/home?region=eu-north-1][(link)]]

Example in book uses an Ubuntu Server image. Found this Ubuntu server:
Ubuntu Server 22.04 LTS (HVM), SSD Volume Type
ami-064087b8d355e9051 (64-bit (x86)) 
*** Creating an ssh key pair for the terraform AWS role
Option to create a new ssh key pair showed in Launch Instance
wizard. It can probably be found in user security settings.
Chosen ed25519 key.
It is weird that I don't just upload my public key.
*** Processing the .pem key file from AWS
The .pem file of a ed25519 key is different than rsa, it is already in
openSSH format.
To get a private key out of it we use the '-y' option with ssh-keygen

`ssh-keygen -y -f keyfile_openssh > keyfile.pub`
*** Choosing between t2 and t3 instances
When trying to create an instance manually, a t3 instance was chosen
as default. Never heard of them and thought that world has moved on
from t2 to t3. Book said t2, so maybe the book wasn't actual either.

Short research showed that t3 is indeed the successor of t2. It has
better performance to price ratio and better networking
capabilities. T2 is still slightly cheaper, so going with t2, this
time.

Book advises checking things like that in Terraform Documentation.
*** Creating an main.tf file
provider "aws" {
  region = "eu-north-1"
}

resource "aws_instance" "teruarc2-1" {
  ami ="ami-064087b8d355e9051"
  instance_type = "t2.nano"

  credit_specification {
    cpu_credits = "standard"
  }
}
**** I've modified instance to nano, since I don't qualify for the free tier anymore.
**** I've added credit_specification to make it a habit so I don't overpay for the t2/t3 instances. They have capacity to go into burst mode with extra CPU capacity, but if it happens too often it costs a lot more per hour. Standard mode makes sure they don't burst often enough to incur extra costs.
*** `terraform init` command to prepare Terraform for action (it downloads provider's code)
Terraform binary doesn't contain the code for any of the
providers. When running terraform init, it scans the code and figures
out what provider code to use. It then downloads that code so it could
be used later.
**** `init` creates a .terraform.lock.hcl file to record the provider selections it has made. This file should be included in version control, to make sure that same choices are made when running `init` with the same code on other machines.
**** `init` has to be run each time the work is started with new Terraform code.
**** `init` can be run multiple times (idempotent).
*** `terraform plan` - is a dry-run command that lets you know what Terraform will do before making any changes.
**** great way to sanity-check code
**** similar to output of the `diff` command
*** 'terraform apply' to build infrastructure based on the code in main.tf
**** it runs terraform plan first anyway and asks for confirmation, so no need to really use 'terraform plan' other than sanity checking while writing code.
*** error when creating instance - t2.nano is not a valid type.
**** aws ec2 describe-instance-types --region eu-north-1

This command will return a list of all the instance types available in the specified region, along with their specifications and pricing information.

You can use this output to choose a proper instance type that meets the requirements of your Terraform plan, and update the Terraform configuration accordingly. In your case, since the error message indicates that the t2.nano instance type does not exist, you can use the output of the above command to choose an alternative instance type that is available in the eu-north-1 region and meets your requirements.

Once you have updated the Terraform configuration, you can run the
terraform plan command again to verify that the changes have resolved
the error.

There were no t2 instances, had to use t3.
*** Adding name to an instance using 'tags'.
provider "aws" {
  region = "eu-north-1"
}

resource "aws_instance" "teruarc2-1" {
  ami ="ami-064087b8d355e9051"
  instance_type = "t3.nano"

  tags = {
    Name = "terraform-example"
  }

  credit_specification {
    cpu_credits = "standard"
  }
}
**** Note that Terraform doesn't destroy the currently active instance, but just modifies it.
**** A name appears next to our instance in the instances list.
**** Trying again, this time observing the console and measuring how much time does it take.
**** I clicked something and the list refreshed. The instance refreshed with a new name.
*** Created a .gitignore by copying one from another project and adding files to be ignored by terraform.
#+BEGIN_SRC ruby

# Emacs
\#*\#
*\~

# Vagrant/Virtualbox files/logs
*.log
.vagrant/

## Debugging files
# DB dumpfiles used for debugging
*.dump
# Temporary files
temp*
# Script output files used for debugging
*.out

# Backup files
*.bak.*

# Certs
acme.json

# Terraform files
.terraform/
*.tfstate
*.tfstate.backup
#+END_SRC
**** In short, we stage the lock file, but ignore the *.tfstate* files and .terraform/ dir.
*** Created a github repository with the 'gh' command.
gh repo create terraformupandrunning
**** Added the repo as remote for the local git repo.
git remote add origin git@github.com:Ignacy-s/terraformupandrunning.git
**** Set the repo default remote repo, the -u option is what sets the upstream.
git push -u origin master
** Deploying a single web server
We are creating the simplest possible web server that just replies
with hello world to HTTP requests. Author of the book is using a super
cool method I've never seen before. It's a bash script creating
index.xhtml file with only Hello World inside it. And then it runs
busybox to host it on port 8080. That's super interesting. I've met
busybox before on a router. I didn't know it had so many options.


#+BEGIN_SRC bash
  user_data = <<-EOF
              #!/bin/bash
              echo "Hello, World" > index.html
              nohup busybox httpd -f -p 8080 &
              EOF

  user_data_replace_on_change = true
#+END_SRC
*** Note that web server is wrapped in 'nohup' and an ampersand (&). This way it can keep running in the background while the bash script can exit.
*** Port used is 8080 instead of default http port 80, this is because:
**** Listening on ports under 1024 requires root privileges. A compromised server with root privileges gives an attacker a free hand on the server
**** Because of the above, it's a best practice to run the server with a non-root user, which therefore has to listen on a higher port.
**** An alternative, not mentioned in the book, is to use 'setcap' (available since kernel 2.2 from 1999) to allow web server to bind to privileged ports without giving it root privileges. This has the downside of allowing web server to bind on ALL privileged ports.
*** Using "User Data" to pass the script to the instance. 
**** Code:
#+BEGIN_SRC terraform
  resource "aws_instance" "teruarc2-1" {
    ami ="ami-064087b8d355e9051"
    instance_type = "t3.nano"

    tags = {
      Name = "terraform-is-up"
    }

    user_data = <<-EOF
      #!/bin/bash
      echo "Hello World!" > index.html
      nohup busybox httpd -f -p 8080 &
      EOF
  
    user_data_replace_on_change = true

  ...
  }
#+END_SRC
***** Note the Terraform's heredoc syntax that is similar to bash's
****** Start: <<-EOF
****** End: EOF
***** Note the "user_data_replace_on_change". Terraform only updates the machine by default. Since User Data is executed only on the first boot, changing it might not have worked as expected, hence we force redeployment of the machine if User Data is changed.
**** User Data - is a feature of AWS EC2 that allows users to run scripts or commands on instances after they are launched. It's a way to automate the configuration of instances after the boot. (Explained it here, because I found the name confusing).
*** Create a security group (so the instance can receive traffic)
**** Code:
#+BEGIN_SRC bash
resource "aws_security_group" "instance" {
  name = "terraform-example-instance"

  ingress {
    from_port = 8080
    to_port = 8080
    protocol = "tcp"
    cidr_blocks =  ["0.0.0.0/0"]
  }
}
#+END_SRC
**** A security group is an equivalent of a firewall for AWS cloud instances. Traffic not allowed in the security group wont reach the instance.
**** CIDR blocks specify IP address ranges in AWS EC2 security groups. They control access to instances by defining source/destination IP ranges for rules. Example: <your-ip-address>/32 allows access only from a single IP.
**** CIDR block of 0.0.0.0/0 is a special block that includes all IP addresses.
*** Terraform expressions - an expression in Terraform is anything that returns a value.
**** 'literals' are the simplest form of an expression. For example a string "abc" or a number 50.
**** 'reference' expression can access values from other parts of code.
*** Using reference expression to get security group's id
**** This is called a 'resource attribute reference' and can be found as such in the Terraform documentation.
**** Syntax: <PROVIDER>_<TYPE>.<NAME>.<ATTRIBUTE>
***** PROVIDER - aws, scaleway, gcp
***** TYPE - type of a resource
***** NAME - name we have given this resource
***** ATTRIBUTE - either one of the arguments of that resource or one of the attributes exported by that resource (list for each resource can be found in documentation)
***** Example usage: aws_security_group.instance.id
**** Code:
#+BEGIN_SRC terraform
  resource "aws_instance" "teruarc2-2" {
    ami ="ami-064087b8d355e9051"
    instance_type = "t3.nano"
    vpc_security_group_ids = [aws_security_group.instance.id]
    tags = {
      Name = "terraform-is-up"
    }
  ...
#+END_SRC
****  Note that the reference is enclosed in square brackets ("[" and "]"). This is not because a reference must be enclosed in square brackets, but because the vpc_security_group_ids attribute expects a list. In HCL (.hcl) files, including Terraform configuration files, square brackets are used to create a list.
*** Dependencies in Terraform
**** A reference from one resource to another creates an 'implicit dependency', which is later used by Terraform in creating the 'dependency graph'.
**** After parsing the code for dependencies and building a 'dependency graph', Terraform knows which resources to create first.
**** In our case, Terraform would know to create the security group before the instance.
**** 'terraform graph' command will print a graph of dependencies in our code.
*** Running 'terraform apply' - where we can see a new symbol and a new phrase
**** '-/+' which is shown next to part of infrastructure that are to be replaced
**** '# forces replacement' which marks the entry that caused the replacement
**** This is an example of 'immutable infrastructure' paradigm.
*** Testing server with 'curl http://IPADDRESS:8080' - server returns "Hello World!"
**** Changing the Hello World reply to something else and trying once again.
**** Code for bash one-liner to automatically curl the instance no-matter what's the new IP address
#+BEGIN_SRC bash
  # This code will pull the instances IP from terraform and then curl
  # it.
  instance_ip=$(terraform show \
                   | awk '/public_ip / \
                   { gsub ( /"/, "", $3 ) ; \
                   print $3 }' )
  curl http://"${instance_ip}":8080
#+END_SRC
**** awk usage explained:
***** terraform show - prints data on all components of the current terraform project
***** awk '/public_ip / - starts awk and tells it to only grep lines containing "public_ip ". Note the space that is included in that string. Otherwise we also grep lines where public_ip is a part of a larger string.
***** gsub () - global substitution is a sed-like builtin function in awk
***** ( /"/, "", $3 ) - replaces all double quotes (/"/) with an empty string (""), in other words deletes them, in the third component of the grepped line ($3)
***** print $3 - prints the modified third component of the line
*** AWS Network Security Interlude (what are AWS VPC and subnets)
**** Each VPC is partitioned into one or more subnets, each with its own IP addresses
***** In order to keep book examples simple, they use the default VPC and it's subnets
***** All default subnets are *public subnets*, accessible from the public internet
**** Running a server in a public subnet is a security risk
***** It's fine for a quick experiment, when you are learning how to use the cloud
***** The public internet is constantly scanned for vulnerable servers, and even a single vulnerability can be exploited by attackers to break into a server. It is crucial to ensure that all ports are properly protected and that all software running on the server is up-to-date with the latest security patches to prevent unauthorized access.
**** Limiting the risk by keeping the production servers in private subnets
***** At least database servers should be inaccessible from the public internet
***** Deploying a reverse proxy or load balancer allow to hide all other infrastructure in private subnets
***** Such load balancer/reverse proxy can then be hardened. Limiting it's purpose helps with the hardening.

** Deploying a configurable web server
*** Introduction to input variables in Terraform
**** Using variables keeps the code cleaner and easier to read.
**** Being able to change value of a variable in one place ensures we don't create problems by forgetting to update the value in some place and not the other.
**** 'input variables' syntax:
#+BEGIN_SRC terraform
  variable "NAME" {
    [CONFIG ...]
  }
#+END_SRC
**** Variable body can contain:
***** description - documents the variable for others (and yourself)
***** default - default value, to avoid prompting user for value if it's not set
***** type - specifies the variable's data type (string, number, bool, etc.)
***** validation - allows defining custom validation rules for variable values
***** sensitive - marks the variable as sensitive, hiding its value from logs and output
**** Variables can be set by:
***** -var option - supplied on the command line when calling `terraform`
****** example: `terraform apply -var boiling_eggs=true`
***** -var-file option - a link to a file with values supplied on the command line when calling `terraform`
****** example: `terraform apply -var-file secrets_file
***** TF_VAR_<variable_name> - environment variables in the shell where `terraform` is run
****** example: export TF_VAR_boiling_eggs=true
***** prompting the user for value, if there is no default and the variable is not set any other place
****** example: terraform asks you "Do you want 'boiling_eggs'?"
**** Variable definition examples:
***** A variable that only accepts numerical values:
#+BEGIN_SRC terraform
  variable "number_example" {
    description = "An example of a number variable in Terraform"
    type        = number
    default     = 42
  }
#+END_SRC
***** A variable that only accepts a list as it's value:
#+BEGIN_SRC terraform
  variable "list_example" {
    description = "An example of a list in Terraform"
    type        = list
    default     = ["a", "b", "c"]
  }
#+END_SRC
***** A variable that only accepts boolean values:
#+BEGIN_SRC terraform
  variable "bool_example" {
    description = "An example of a boolean variable in Terraform"
    type = bool
    default = true
  }
#+END_SRC
***** A variable that only accepts a map as its value:
#+BEGIN_SRC terraform
  variable "map_example" {
    description = "An example of a map in Terraform"
    type = map(string)
    default = {
      key1 = "value1"
      key2 = "value2"
    }
  }
#+END_SRC
***** A variable with custom validation:
#+BEGIN_SRC terraform
  variable "validated_example" {
    description = "An example of a variable with custom validation in Terraform"
    type = string
    default = "example"

    validation {
      condition     = length(var.validated_example) > 5
      error_message = "The string must be at least 6 characters long."
    }
  }
#+END_SRC
***** Combined variable - a list input variable where all list items are numbers:
#+BEGIN_SRC terraform
  variable "list_of_numbers_example" {
    description = "An example of a list of numbers in Terraform"
    type = list(number)
    default = [1, 2, 3, 4, 5]
  }
#+END_SRC
***** Combined variable - a map that requires all of the values to be strings:
#+BEGIN_SRC terraform
  variable "map_of_strings_example" {
    description = "An example of a map of strings in Terraform"
    type = map(string)
    default = {
      key1 = "value1"
      key2 = "value2"
      key3 = "value3"
    }
  }
#+END_SRC
***** A structural type example using the object type:
#+BEGIN_SRC terraform
  variable "object_example" {
    description = "An example of a structural type in Terraform"
    type        = object({
      name    = string
      age     = number
      tags    = list(string)
      enabled = bool
    })

    default = {
      name    = "value1"
      age     =  42
      tags    = ["a", "b", "c"]
      enabled = true
    }
  }
#+END_SRC
***** A structural type for a database config:
#+BEGIN_SRC terraform
variable "database_config" {
  description = "Configuration for the database"
  type = object({
    name = string
    engine = string
    port = number
    replication = bool
    replicas = list(string)
  })

  default = {
    name = "my_database"
    engine = "postgres"
    port = 5432
    replication = true
    replicas = ["replica1", "replica2"]
  }
}
#+END_SRC
**** Setting a variable with a wrong type will result in Terraform signaling an error when running `terraform apply` with that variable.
*** Creating a variable to store the port number:
#+BEGIN_SRC terraform
  variable "server_port" {
    description = "The port the server will use for HTTP requests"
    type        = number
  }
#+END_SRC
*** Running `terraform apply` to test how Terraform will react if the variable has not been set
*** Variable reference - using our defined variables in the Terraform code
**** Syntax: var.<VARIABLE_NAME>
***** Example: to_port = var.server_port
**** When used inside a string, use *interpolation*
**** Interpolation syntax: "${ ... }"
***** Example:
#+BEGIN_SRC terraform
  user_data = <<-EOF
    #!/bin/bash
    echo "It really works, my friend!" > index.html
    nohup busybox httpd -f -p ${var.server_port} &
    EOF
#+END_SRC
*** Introduction to output variables in Terraform
**** Output variables provide a way to display data from your Terraform configuration.
**** They can be used to display important information, such as IP addresses, user names, or other values you might need to share.
**** 'output variables' syntax:
#+BEGIN_SRC terraform
output "NAME" {
[CONFIG ...]
}
#+END_SRC
**** Output body can contain:
***** description - documents the output variable for others (and yourself)
***** value - defines the value of the output variable
***** sensitive - marks the output variable as sensitive, hiding its value from logs and output
***** depends_on - list of resources that the output depends on, ensuring they are created before the output is computed
**** Output variables are displayed after a successful terraform apply or can be displayed on demand using terraform output command.
**** Output variable definition examples:
***** A simple output variable:
#+BEGIN_SRC terraform
  output "simple_example" {
    description = "An example of a simple output variable in Terraform"
    value = "Hello, World!"
  }
#+END_SRC
***** An output variable that displays an IP address:
#+BEGIN_SRC terraform
  output "ip_address" {
    description = "The public IP address of the instance"
    value = aws_instance.example.public_ip
  }
#+END_SRC
***** An output variable marked as sensitive:
#+BEGIN_SRC terraform
  output "sensitive_example" {
    description = "An example of a sensitive output variable in Terraform"
    value = aws_security_group.example.id
    sensitive = true
  }
#+END_SRC
***** An output variable with depends_on:
#+BEGIN_SRC terraform
  output "depends_on_example" {
    description = "An example of an output variable with depends_on in Terraform"
    value = aws_eip.example.public_ip
    depends_on = [aws_instance.example]
  }
#+END_SRC
***** A list output variable:
#+BEGIN_SRC terraform
  output "list_example" {
    description = "An example of a list output variable in Terraform"
    value = aws_instance.example.*.public_ip
  }
#+END_SRC
***** A map output variable:
#+BEGIN_SRC terraform
  output "map_example" {
    description = "An example of a map output variable in Terraform"
    value = {
      instance_id = aws_instance.example.id
      public_ip = aws_instance.example.public_ip
    }
  }
#+END_SRC
***** A structural type example using the object type:
#+BEGIN_SRC terraform
  output "object_example" {
    description = "An example of a structural output type in Terraform"
    value = {
      instance_id = aws_instance.example.id
      public_ip = aws_instance.example.public_ip
      tags = aws_instance.example.tags
    }
  }
#+END_SRC
***** An output variable for a database config:
#+BEGIN_SRC terraform
  output "database_config" {
    description = "Output for the database configuration"
    value = {
      name = var.database_config.name
      engine = var.database_config.engine
      port = var.database_config.port
      replication = var.database_config.replication
      replicas = var.database_config.replicas
    }
  }
#+END_SRC
**** If an output variable is marked as sensitive, its value will be hidden from logs and output, but can still be accessed by other Terraform configurations or modules using the terraform_remote_state data source.
*** Using output variable to have terraform return server's public IP after running the terraform playbook
**** Code:
#+BEGIN_SRC terraform
output "public_ip" {
  value        = aws_instance.terurarc2-3.public_ip
  description  = "The public IP address of the web server"
}
#+END_SRC
**** Running `terraform apply` resulted in Terraform returning server's IP address at the end of the prompt.
*** Using `terraform output` to list all outputs without applying changes:
#+BEGIN_SRC bash
$ terraform output
public_ip = "16.16.91.66"
#+END_SRC
*** Using `terraform output <OUTPUT_NAME>` to see the value of a specific output called <OUTPUT_NAME>
#+BEGIN_SRC bash
$ terraform output public_ip
"16.16.91.66"
#+END_SRC
**** This approach is especially useful for scripts and automation. By utilizing Terraform to set up the infrastructure and then using terraform output to retrieve specific values, you can seamlessly integrate with other tools that interact with the created infrastructure.
** Deploying a cluster of web servers
*** In real world usage, a single server is a single point of failure. To increase resiliency and availability we can run a cluster of servers instead. The concept of auto-scaling resources is not unique to AWS, but in this case this is the cloud provider we are using.
*** ASG - AWS' Auto Scaling Group automates many tasks in auto-scaling cluster management:
**** launching a cluster of EC2 Instances
**** monitoring the health of each Instance
**** replacing failed Instances
**** adjusting the size of the cluster in response to load
*** 'launch configuration' - specifies how to configure each EC2 Instance in the ASG
**** 'aws_launch_configuration' resource is nearly identical to the 'aws_instance' resource
***** but it doesn't support 'tags' and 'user_data_replace_on_change' parameter
***** two parameters have different name:
****** 'ami' becomes 'image_id'
****** 'vpc_security_group' becomes 'security_groups'
*** Modifying our main configuration file to use Auto Scaling Group instead of just one Instance
**** Changing the 'aws_instance' to 'aws_launch_configuration'
#+BEGIN_SRC diff
 
-resource "aws_instance" "teruarc2-3" {
-  ami ="ami-064087b8d355e9051"
+resource "aws_launch_configuration" "examplenton" {
+  image_id ="ami-064087b8d355e9051"
   instance_type = "t3.nano"
-  vpc_security_group_ids = [aws_security_group.instance.id]
-  tags = {
-    Name = "terraform-is-up"
-  }
+  security_groups = [aws_security_group.instance.id]
 
   user_data = <<-EOF
     #!/bin/bash
     echo "It really works, my friend!" > index.html
     nohup busybox httpd -f -p ${var.server_port} &
     EOF
-  
-  user_data_replace_on_change = true
#+END_SRC
**** Adding 'aws_autoscaling_group" resource
#+BEGIN_SRC terraform
  resource "aws_autoscaling_group" "example" {
    launch_configuration =
    aws_launch_configuration.examplenton.name

    min_size = 2
    max_size = 10

    tag {
      key                 = "Name"
      value               = "terraform-asg-example"
      propagate_at_launch = true
    }
  }
#+END_SRC
***** Note the launch_configuration name filled in as reference
*** Avoiding dependency hell when modifying launch configuration:
**** Launch configurations are immutable, meaning you cannot modify them directly.
**** When you change a launch configuration, Terraform will create a new one with the updated settings, which can cause issues if your ASG still references the old launch configuration.
**** To avoid these issues, use the create_before_destroy lifecycle setting. With this setting enabled, Terraform will create the new launch configuration first, update the ASG to reference it, and then delete the old launch configuration, ensuring a smooth update process for your infrastructure.
**** Adding lifecycle settings:
#+BEGIN_SRC terraform
  [... inside the launch configuration resource definition]

  # Required when using a launch configuration with an auto scaling
  # group.
  lifecycle {
    create_before_destroy = true
  }
  #+END_SRC
*** Introduction to 'data sources'
**** A 'data source' is a piece of read-only information fetched from the provider every time Terraform is run
**** Adding a data source to Terraform configuration does not change the described infrastructure
**** Using a 'data source' is just a way to query provider's API for data and make it available to the rest of your Terraform code
**** Examples of data that can be queried with 'data sources':
***** VPC data
***** subnet data
***** AMI id's
***** IP address ranges
***** current user's identity
***** [and many others]
**** Syntax:
#+BEGIN_SRC terraform
  data "<PROVIDER>_<TYPE>" "<NAME>" {
    [CONFIG ...]
  }
#+END_SRC
***** PROVIDER: name of the provider (f.ex. aws)
***** TYPE: type of data source (f.ex. vpc)
***** NAME: identifier given to this data source to be used throughout the Terraform code
***** CONFIG: one or more arguments specific to this data source
**** Example:
#+BEGIN_SRC terraform
  data "aws_vpc" "default" {
    default = true
  }
#+END_SRC
***** Arguments in the body of the data source are usually search filters indicating what information you're looking for.
***** 'default = true' tell Terraform to look for the default VPC in your AWS account. It's not connected to the name 'default' which was given by us to this data source.
**** Getting data out of data source: 'data.<PROVIDER>_<TYPE>.<NAME>.<ATTRIBUTE>'
***** Example: 'data.aws_vpc.default.id' to get the ID number of the VPC
*** Using a data source to finish autoscaling group definition by automatically getting an AWS subnet ID.
**** Define a subnet data source:
#+BEGIN_SRC terraform
data "aws_subnets" "default" {
  filter {
    name = "vpc-id"
    values = [data.aws_vpc.default.id]
  }
}
#+END_SRC
Note how we used the previously defined data source of vpc to get it's
ID number.
**** Pull the subnet IDs from the data source and pass them to the ASG definition
#+BEGIN_SRC bash
resource "aws_autoscaling_group" "example" {
  launch_configuration = aws_launch_configuration.examplenton.name
  vpc_zone_identifier  = data.aws_subnets.default.ids

  min_size = 2
  max_size = 10

  tag {
    key                 = "Name"
    value               = "terraform-asg-example"
    propagate_at_launch = true
  }
}
#+END_SRC
*** Running 'terraform apply' to stand up newly defined autoscaling group.
It worked nicely.
** Deploying a load balancer
** Cleaning up

* Extras:
** Adding terraform dotfiles to Syncthing's .gitignore.
Syncthing's .gitignore is not really called gitignore but .stignore.
*** Asked GPT about which files to ignore. It's answer was nearly identical to what stood in Terraform docs (for files that shouldn't be versioned) with one caveat - it suggested to not sync the lock file. It might have been because of how I formed my prompt, comparing the situation of syncing terraform files with when syncing .vagrant dir between machines caused a lot of problems.
*** The new .stignore file:
#+BEGIN_SRC bash
# Ignore Vagrant's data relevant only to the current machine
.vagrant

# Ignore .terraform directory
.terraform/

# Ignore Terraform state files
terraform.tfstate
terraform.tfstate.backup

# Ignore the Terraform lock file
.terraform.lock.hcl
#+BEGIN_SRC bash
*** Sharing terraform.tfstate and .terraform.lock.hcl across machines poses certain risks if project changes were performed on both of the machines simultaneously. In my case, with just me accessing these files, there is hardly any risk.
*** Deciding to synchronize the lock file and the state files.
*** Newer .stignore file:
#+BEGIN_SRC text
# Ignore Vagrant's data relevant only to the current machine                             
.vagrant

# Ignore .terraform directory
.terraform/

# # Commenting this out to allow for syncing of the Terraform state
# # across multiple machines.
# # Ignore Terraform state files
# terraform.tfstate
# terraform.tfstate.backup
# # Ignore the Terraform lock file
# .terraform.lock.hcl
#+END_SRC


** TODO Configure Terraform to use an S3 bucket for state.

** Committing only some changes to a file.
*** Yes, it's possible both with command line git and with emacs magit.
*** Source: GPT-4: is it possible to use magit or git to commit only some of modifications to a file?

Yes, it is possible to commit only some modifications to a file using both Magit and Git.

For Magit:

    Open the Magit status buffer by typing M-x magit-status.
    Navigate to the modified file in the status buffer.
    Press TAB to expand the file's hunks (changes).
    Move the cursor to the hunk you want to stage and press s to stage it. You can stage multiple hunks by repeating this step.
    When you have staged the desired hunks, press c c to start a commit.
    Write a commit message and press C-c C-c to finalize the commit.

For Git command line:

    Use git add -p or git add --patch. This command will allow you to interactively stage hunks from the modified file.
    Git will show each hunk and ask if you want to stage it. Answer with y (yes), n (no), or other options based on your needs.
    After you've staged the desired hunks, use git commit -m "Your commit message" to commit the staged changes.

In both cases, you can commit only specific changes within a file, leaving the remaining modifications unstaged.

